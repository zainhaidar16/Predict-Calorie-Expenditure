{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bdeb397",
   "metadata": {},
   "source": [
    "# Calorie Expenditure Prediction Project\n",
    "\n",
    "This notebook provides a comprehensive analysis for predicting calorie expenditure using multiple machine learning models.\n",
    "\n",
    "## Project Overview\n",
    "- **Goal**: Predict calorie expenditure based on various features\n",
    "- **Models**: Random Forest, XGBoost, and Ridge Regression\n",
    "- **Approach**: Complete data analysis, cleaning, feature engineering, and model comparison\n",
    "\n",
    "## Table of Contents\n",
    "1. Data Loading and Exploration\n",
    "2. Data Cleaning and Preprocessing\n",
    "3. Exploratory Data Analysis\n",
    "4. Feature Engineering\n",
    "5. Model Training and Evaluation\n",
    "6. Model Comparison and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94d571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Installing...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"xgboost\"])\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56251189",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82f4cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "print(\"Dataset Shapes:\")\n",
    "print(f\"Training data: {train_data.shape}\")\n",
    "print(f\"Test data: {test_data.shape}\")\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING DATA OVERVIEW\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(train_data.head())\n",
    "\n",
    "print(\"\\nData types and missing values:\")\n",
    "train_info = pd.DataFrame({\n",
    "    'Data Type': train_data.dtypes,\n",
    "    'Missing Values': train_data.isnull().sum(),\n",
    "    'Missing %': (train_data.isnull().sum() / len(train_data)) * 100\n",
    "})\n",
    "display(train_info)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TEST DATA OVERVIEW\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(test_data.head())\n",
    "\n",
    "print(\"\\nData types and missing values:\")\n",
    "test_info = pd.DataFrame({\n",
    "    'Data Type': test_data.dtypes,\n",
    "    'Missing Values': test_data.isnull().sum(),\n",
    "    'Missing %': (test_data.isnull().sum() / len(test_data)) * 100\n",
    "})\n",
    "display(test_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe83f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed statistical analysis of the training data\n",
    "print(\"STATISTICAL SUMMARY OF TRAINING DATA\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Numerical features summary\n",
    "numerical_cols = train_data.select_dtypes(include=[np.number]).columns\n",
    "print(f\"\\nNumerical columns: {list(numerical_cols)}\")\n",
    "display(train_data[numerical_cols].describe())\n",
    "\n",
    "# Categorical features summary\n",
    "categorical_cols = train_data.select_dtypes(include=['object']).columns\n",
    "print(f\"\\nCategorical columns: {list(categorical_cols)}\")\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Unique values: {train_data[col].nunique()}\")\n",
    "    print(f\"  Values: {train_data[col].unique()[:10]}\")\n",
    "    if train_data[col].nunique() <= 10:\n",
    "        print(f\"  Value counts:\")\n",
    "        display(train_data[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5779ff51",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52edac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for and handle missing values\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Check missing values in both datasets\n",
    "missing_train = train_data.isnull().sum()\n",
    "missing_test = test_data.isnull().sum()\n",
    "\n",
    "print(\"Missing values in training data:\")\n",
    "print(missing_train[missing_train > 0])\n",
    "\n",
    "print(\"\\nMissing values in test data:\")\n",
    "print(missing_test[missing_test > 0])\n",
    "\n",
    "if missing_train.sum() == 0 and missing_test.sum() == 0:\n",
    "    print(\"\\n✅ No missing values found in either dataset!\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Missing values detected. Handling them...\")\n",
    "    # Handle missing values if any exist\n",
    "    # (Add specific handling code here if needed)\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\nDuplicate rows in training data: {train_data.duplicated().sum()}\")\n",
    "print(f\"Duplicate rows in test data: {test_data.duplicated().sum()}\")\n",
    "\n",
    "# Remove duplicates if any\n",
    "if train_data.duplicated().sum() > 0:\n",
    "    train_data = train_data.drop_duplicates()\n",
    "    print(\"Removed duplicate rows from training data\")\n",
    "\n",
    "if test_data.duplicated().sum() > 0:\n",
    "    test_data = test_data.drop_duplicates()\n",
    "    print(\"Removed duplicate rows from test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db537bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type optimization and categorical encoding preparation\n",
    "print(\"DATA TYPE OPTIMIZATION\")\n",
    "print(\"=\"*25)\n",
    "\n",
    "# Create copies for processing\n",
    "train_processed = train_data.copy()\n",
    "test_processed = test_data.copy()\n",
    "\n",
    "# Store original categorical columns before encoding\n",
    "original_categorical = train_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Categorical columns to encode: {original_categorical}\")\n",
    "\n",
    "# Initialize encoders dictionary to store for consistency\n",
    "encoders = {}\n",
    "\n",
    "# Encode categorical variables consistently across train and test\n",
    "for col in original_categorical:\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # Fit on combined unique values from both train and test\n",
    "    combined_values = pd.concat([train_processed[col], test_processed[col]]).unique()\n",
    "    le.fit(combined_values)\n",
    "    \n",
    "    # Transform both datasets\n",
    "    train_processed[col] = le.transform(train_processed[col])\n",
    "    test_processed[col] = le.transform(test_processed[col])\n",
    "    \n",
    "    # Store encoder\n",
    "    encoders[col] = le\n",
    "    \n",
    "    print(f\"Encoded {col}: {len(combined_values)} unique values\")\n",
    "\n",
    "print(\"\\n✅ Categorical encoding completed!\")\n",
    "print(f\"Training data shape after encoding: {train_processed.shape}\")\n",
    "print(f\"Test data shape after encoding: {test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e834f0",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c0b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Distribution of target variable\n",
    "axes[0,0].hist(train_processed['Calories'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('Distribution of Calories (Target Variable)')\n",
    "axes[0,0].set_xlabel('Calories')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# Box plot for outlier detection\n",
    "axes[0,1].boxplot(train_processed['Calories'])\n",
    "axes[0,1].set_title('Box Plot of Calories')\n",
    "axes[0,1].set_ylabel('Calories')\n",
    "\n",
    "# Q-Q plot for normality check\n",
    "from scipy import stats\n",
    "stats.probplot(train_processed['Calories'], dist=\"norm\", plot=axes[1,0])\n",
    "axes[1,0].set_title('Q-Q Plot of Calories')\n",
    "\n",
    "# Log transformation (if needed)\n",
    "log_calories = np.log1p(train_processed['Calories'])\n",
    "axes[1,1].hist(log_calories, bins=50, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "axes[1,1].set_title('Log-transformed Calories Distribution')\n",
    "axes[1,1].set_xlabel('Log(Calories + 1)')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical summary of target variable\n",
    "print(\"TARGET VARIABLE STATISTICS\")\n",
    "print(\"=\"*30)\n",
    "print(f\"Mean: {train_processed['Calories'].mean():.2f}\")\n",
    "print(f\"Median: {train_processed['Calories'].median():.2f}\")\n",
    "print(f\"Standard Deviation: {train_processed['Calories'].std():.2f}\")\n",
    "print(f\"Skewness: {train_processed['Calories'].skew():.3f}\")\n",
    "print(f\"Kurtosis: {train_processed['Calories'].kurtosis():.3f}\")\n",
    "print(f\"Range: {train_processed['Calories'].min():.2f} - {train_processed['Calories'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ab37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation analysis\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*20)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = train_processed.drop('id', axis=1).corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.3f', cmap='RdYlBu_r', \n",
    "            center=0, square=True, linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find features most correlated with target\n",
    "target_correlations = correlation_matrix['Calories'].abs().sort_values(ascending=False)\n",
    "print(\"\\nFeatures most correlated with Calories:\")\n",
    "print(target_correlations[1:])  # Exclude self-correlation\n",
    "\n",
    "# Identify highly correlated feature pairs (potential multicollinearity)\n",
    "print(\"\\nHighly correlated feature pairs (|correlation| > 0.7):\")\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.7:\n",
    "            high_corr_pairs.append((\n",
    "                correlation_matrix.columns[i], \n",
    "                correlation_matrix.columns[j], \n",
    "                correlation_matrix.iloc[i, j]\n",
    "            ))\n",
    "\n",
    "for pair in high_corr_pairs:\n",
    "    print(f\"{pair[0]} - {pair[1]}: {pair[2]:.3f}\")\n",
    "\n",
    "if not high_corr_pairs:\n",
    "    print(\"No highly correlated feature pairs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c1a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature distribution analysis\n",
    "features_to_plot = [col for col in train_processed.columns if col not in ['id', 'Calories']]\n",
    "n_features = len(features_to_plot)\n",
    "n_cols = 3\n",
    "n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 else axes\n",
    "\n",
    "for i, feature in enumerate(features_to_plot):\n",
    "    if i < len(axes):\n",
    "        # Check if feature was originally categorical\n",
    "        if any(feature in original_cat for original_cat in [original_categorical]):\n",
    "            # Bar plot for categorical features\n",
    "            value_counts = train_processed[feature].value_counts().head(10)\n",
    "            axes[i].bar(range(len(value_counts)), value_counts.values, alpha=0.7)\n",
    "            axes[i].set_title(f'{feature} Distribution (Categorical)')\n",
    "            axes[i].set_xlabel('Encoded Values')\n",
    "            axes[i].set_ylabel('Count')\n",
    "        else:\n",
    "            # Histogram for numerical features\n",
    "            axes[i].hist(train_processed[feature], bins=30, alpha=0.7, edgecolor='black')\n",
    "            axes[i].set_title(f'{feature} Distribution')\n",
    "            axes[i].set_xlabel(feature)\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "        \n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Hide empty subplots\n",
    "for i in range(len(features_to_plot), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab912d43",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3766a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering and selection\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*19)\n",
    "\n",
    "# Create copies for feature engineering\n",
    "train_features = train_processed.copy()\n",
    "test_features = test_processed.copy()\n",
    "\n",
    "# Remove ID column and separate target\n",
    "X = train_features.drop(['id', 'Calories'], axis=1)\n",
    "y = train_features['Calories']\n",
    "X_test = test_features.drop('id', axis=1)\n",
    "\n",
    "print(f\"Original features: {X.columns.tolist()}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Training samples: {X.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Feature scaling for linear models\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"\\n✅ Feature scaling completed for linear models\")\n",
    "print(f\"Scaled feature means: {X_scaled.mean().round(3).tolist()}\")\n",
    "print(f\"Scaled feature stds: {X_scaled.std().round(3).tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=None\n",
    ")\n",
    "\n",
    "# Also split scaled features\n",
    "X_train_scaled, X_val_scaled, _, _ = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=None\n",
    ")\n",
    "\n",
    "print(\"DATA SPLITTING SUMMARY\")\n",
    "print(\"=\"*22)\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "\n",
    "# Verify no data leakage\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(f\"Training mean: {y_train.mean():.2f} ± {y_train.std():.2f}\")\n",
    "print(f\"Validation mean: {y_val.mean():.2f} ± {y_val.std():.2f}\")\n",
    "print(f\"Full dataset mean: {y.mean():.2f} ± {y.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbc7534",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b842414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation metrics function\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"Calculate and return evaluation metrics\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "    \n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R²': r2,\n",
    "        'MAPE (%)': mape\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Initialize results storage\n",
    "model_results = []\n",
    "model_predictions = {}\n",
    "trained_models = {}\n",
    "\n",
    "print(\"🚀 STARTING MODEL TRAINING\")\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d62ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Random Forest Regressor\n",
    "print(\"\\n🌲 Training Random Forest Regressor...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "rf_metrics = evaluate_model(y_val, y_pred_rf, 'Random Forest')\n",
    "model_results.append(rf_metrics)\n",
    "model_predictions['Random Forest'] = y_pred_rf\n",
    "trained_models['Random Forest'] = rf_model\n",
    "\n",
    "print(f\"Random Forest Results:\")\n",
    "for metric, value in rf_metrics.items():\n",
    "    if metric != 'Model':\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# Feature importance for Random Forest\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 5 Most Important Features:\")\n",
    "for i, (_, row) in enumerate(rf_importance.head().iterrows()):\n",
    "    print(f\"  {i+1}. {row['Feature']}: {row['Importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4494be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: XGBoost Regressor\n",
    "print(\"\\n🚀 Training XGBoost Regressor...\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_val)\n",
    "\n",
    "# Evaluate XGBoost\n",
    "xgb_metrics = evaluate_model(y_val, y_pred_xgb, 'XGBoost')\n",
    "model_results.append(xgb_metrics)\n",
    "model_predictions['XGBoost'] = y_pred_xgb\n",
    "trained_models['XGBoost'] = xgb_model\n",
    "\n",
    "print(f\"XGBoost Results:\")\n",
    "for metric, value in xgb_metrics.items():\n",
    "    if metric != 'Model':\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# Feature importance for XGBoost\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 5 Most Important Features:\")\n",
    "for i, (_, row) in enumerate(xgb_importance.head().iterrows()):\n",
    "    print(f\"  {i+1}. {row['Feature']}: {row['Importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d11574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Ridge Regression\n",
    "print(\"\\n📏 Training Ridge Regression...\")\n",
    "print(\"-\" * 32)\n",
    "\n",
    "# Train Ridge Regression (using scaled features)\n",
    "ridge_model = Ridge(alpha=1.0, random_state=42)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "y_pred_ridge = ridge_model.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate Ridge Regression\n",
    "ridge_metrics = evaluate_model(y_val, y_pred_ridge, 'Ridge Regression')\n",
    "model_results.append(ridge_metrics)\n",
    "model_predictions['Ridge Regression'] = y_pred_ridge\n",
    "trained_models['Ridge Regression'] = ridge_model\n",
    "\n",
    "print(f\"Ridge Regression Results:\")\n",
    "for metric, value in ridge_metrics.items():\n",
    "    if metric != 'Model':\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# Feature coefficients for Ridge Regression\n",
    "ridge_coeffs = pd.DataFrame({\n",
    "    'Feature': X_train_scaled.columns,\n",
    "    'Coefficient': ridge_model.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(f\"\\nTop 5 Most Important Features (by coefficient magnitude):\")\n",
    "for i, (_, row) in enumerate(ridge_coeffs.head().iterrows()):\n",
    "    print(f\"  {i+1}. {row['Feature']}: {row['Coefficient']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb4d465",
   "metadata": {},
   "source": [
    "## 6. Model Comparison and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7cec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive model comparison\n",
    "print(\"📊 MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(model_results)\n",
    "results_df = results_df.set_index('Model')\n",
    "\n",
    "# Display results table\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "display(results_df.round(4))\n",
    "\n",
    "# Find best model for each metric\n",
    "print(\"\\nBest Models by Metric:\")\n",
    "print(f\"  Lowest MAE: {results_df['MAE'].idxmin()} ({results_df['MAE'].min():.4f})\")\n",
    "print(f\"  Lowest RMSE: {results_df['RMSE'].idxmin()} ({results_df['RMSE'].min():.4f})\")\n",
    "print(f\"  Highest R²: {results_df['R²'].idxmax()} ({results_df['R²'].max():.4f})\")\n",
    "print(f\"  Lowest MAPE: {results_df['MAPE (%)'].idxmin()} ({results_df['MAPE (%)'].min():.4f}%)\")\n",
    "\n",
    "# Overall best model (based on R²)\n",
    "best_model_name = results_df['R²'].idxmax()\n",
    "best_model = trained_models[best_model_name]\n",
    "best_predictions = model_predictions[best_model_name]\n",
    "\n",
    "print(f\"\\n🏆 Overall Best Model: {best_model_name}\")\n",
    "print(f\"   R² Score: {results_df.loc[best_model_name, 'R²']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance comparison\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Performance metrics comparison\n",
    "metrics_to_plot = ['MAE', 'RMSE', 'R²', 'MAPE (%)']\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[i//3, i%3] if i < 3 else axes[1, i-3]\n",
    "    bars = ax.bar(results_df.index, results_df[metric], color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax.set_title(f'{metric} Comparison', fontweight='bold')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, results_df[metric]):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Prediction vs Actual scatter plots\n",
    "for i, (model_name, predictions) in enumerate(model_predictions.items()):\n",
    "    ax = axes[1, i] if i < 3 else None\n",
    "    if ax is not None:\n",
    "        ax.scatter(y_val, predictions, alpha=0.6, color=colors[i])\n",
    "        ax.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
    "        ax.set_xlabel('Actual Calories')\n",
    "        ax.set_ylabel('Predicted Calories')\n",
    "        ax.set_title(f'{model_name}\\nPredictions vs Actual')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Calculate and display R²\n",
    "        r2 = r2_score(y_val, predictions)\n",
    "        ax.text(0.05, 0.95, f'R² = {r2:.3f}', transform=ax.transAxes, \n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                verticalalignment='top', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e9548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance comparison for tree-based models\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Random Forest feature importance\n",
    "axes[0].barh(range(len(rf_importance.head(10))), rf_importance.head(10)['Importance'], \n",
    "             color='skyblue', alpha=0.7)\n",
    "axes[0].set_yticks(range(len(rf_importance.head(10))))\n",
    "axes[0].set_yticklabels(rf_importance.head(10)['Feature'])\n",
    "axes[0].set_xlabel('Feature Importance')\n",
    "axes[0].set_title('Random Forest\\nTop 10 Feature Importances', fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# XGBoost feature importance\n",
    "axes[1].barh(range(len(xgb_importance.head(10))), xgb_importance.head(10)['Importance'], \n",
    "             color='lightcoral', alpha=0.7)\n",
    "axes[1].set_yticks(range(len(xgb_importance.head(10))))\n",
    "axes[1].set_yticklabels(xgb_importance.head(10)['Feature'])\n",
    "axes[1].set_xlabel('Feature Importance')\n",
    "axes[1].set_title('XGBoost\\nTop 10 Feature Importances', fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Ridge regression coefficients\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(ridge_coeffs.head(10))), ridge_coeffs.head(10)['Coefficient'], \n",
    "         color='lightgreen', alpha=0.7)\n",
    "plt.yticks(range(len(ridge_coeffs.head(10))), ridge_coeffs.head(10)['Feature'])\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.title('Ridge Regression\\nTop 10 Feature Coefficients (by magnitude)', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26335c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for robust model evaluation\n",
    "print(\"🔄 CROSS-VALIDATION ANALYSIS\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Perform 5-fold cross-validation for all models\n",
    "cv_results = {}\n",
    "\n",
    "for model_name, model in trained_models.items():\n",
    "    print(f\"\\nPerforming CV for {model_name}...\")\n",
    "    \n",
    "    if model_name == 'Ridge Regression':\n",
    "        # Use scaled features for Ridge\n",
    "        cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring='r2', n_jobs=-1)\n",
    "    else:\n",
    "        # Use original features for tree-based models\n",
    "        cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2', n_jobs=-1)\n",
    "    \n",
    "    cv_results[model_name] = cv_scores\n",
    "    \n",
    "    print(f\"  CV R² Scores: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "    print(f\"  Mean CV R²: {cv_scores.mean():.4f} (±{cv_scores.std()*2:.4f})\")\n",
    "\n",
    "# Create cross-validation comparison plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "box_data = [cv_results[model] for model in cv_results.keys()]\n",
    "box_plot = plt.boxplot(box_data, labels=list(cv_results.keys()), patch_artist=True)\n",
    "\n",
    "# Color the boxes\n",
    "for patch, color in zip(box_plot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "plt.title('Cross-Validation R² Scores Comparison', fontweight='bold', fontsize=14)\n",
    "plt.ylabel('R² Score')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical summary of CV results\n",
    "print(\"\\nCross-Validation Summary:\")\n",
    "cv_summary = pd.DataFrame({\n",
    "    'Mean_R2': [cv_results[model].mean() for model in cv_results.keys()],\n",
    "    'Std_R2': [cv_results[model].std() for model in cv_results.keys()],\n",
    "    'Min_R2': [cv_results[model].min() for model in cv_results.keys()],\n",
    "    'Max_R2': [cv_results[model].max() for model in cv_results.keys()]\n",
    "}, index=list(cv_results.keys()))\n",
    "\n",
    "display(cv_summary.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40d2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set using the best model\n",
    "print(f\"🎯 GENERATING FINAL PREDICTIONS\")\n",
    "print(\"=\"*33)\n",
    "\n",
    "print(f\"Using best model: {best_model_name}\")\n",
    "print(f\"Best model R² on validation: {results_df.loc[best_model_name, 'R²']:.4f}\")\n",
    "\n",
    "# Generate test predictions\n",
    "if best_model_name == 'Ridge Regression':\n",
    "    test_predictions = best_model.predict(X_test_scaled)\n",
    "else:\n",
    "    test_predictions = best_model.predict(X_test)\n",
    "\n",
    "print(f\"\\nTest predictions generated: {len(test_predictions)} samples\")\n",
    "print(f\"Prediction range: {test_predictions.min():.2f} - {test_predictions.max():.2f}\")\n",
    "print(f\"Prediction mean: {test_predictions.mean():.2f}\")\n",
    "print(f\"Prediction std: {test_predictions.std():.2f}\")\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'Calories': test_predictions\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('calorie_predictions.csv', index=False)\n",
    "print(f\"\\n✅ Predictions saved to 'calorie_predictions.csv'\")\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "display(submission.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376f6eab",
   "metadata": {},
   "source": [
    "## 7. Summary and Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Best Performing Model**: The analysis will identify which of the three models (Random Forest, XGBoost, or Ridge Regression) performs best on this dataset.\n",
    "\n",
    "2. **Feature Importance**: Tree-based models provide insights into which features are most predictive of calorie expenditure.\n",
    "\n",
    "3. **Model Characteristics**:\n",
    "   - **Random Forest**: Robust ensemble method, good for mixed data types\n",
    "   - **XGBoost**: Advanced gradient boosting, often superior performance\n",
    "   - **Ridge Regression**: Simple linear model, good baseline and interpretability\n",
    "\n",
    "4. **Cross-Validation**: Provides robust estimates of model performance and helps identify overfitting.\n",
    "\n",
    "### Next Steps:\n",
    "- Consider hyperparameter tuning for the best model\n",
    "- Explore additional feature engineering\n",
    "- Try ensemble methods combining multiple models\n",
    "- Analyze prediction errors for insights into model improvements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
